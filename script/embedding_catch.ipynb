{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c8ad5e830d481f80a1f095fa1e6ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"/data/yimin/models/base/meta-llama/Meta-Llama-3-8B\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.type of LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict([('inv_freq',\n",
       "               tensor([1.0000e+00, 8.1462e-01, 6.6360e-01, 5.4058e-01, 4.4037e-01, 3.5873e-01,\n",
       "                       2.9223e-01, 2.3805e-01, 1.9392e-01, 1.5797e-01, 1.2869e-01, 1.0483e-01,\n",
       "                       8.5397e-02, 6.9566e-02, 5.6670e-02, 4.6164e-02, 3.7606e-02, 3.0635e-02,\n",
       "                       2.4955e-02, 2.0329e-02, 1.6560e-02, 1.3490e-02, 1.0990e-02, 8.9523e-03,\n",
       "                       7.2927e-03, 5.9407e-03, 4.8394e-03, 3.9423e-03, 3.2114e-03, 2.6161e-03,\n",
       "                       2.1311e-03, 1.7360e-03, 1.4142e-03, 1.1520e-03, 9.3847e-04, 7.6450e-04,\n",
       "                       6.2277e-04, 5.0732e-04, 4.1327e-04, 3.3666e-04, 2.7425e-04, 2.2341e-04,\n",
       "                       1.8199e-04, 1.4825e-04, 1.2077e-04, 9.8381e-05, 8.0143e-05, 6.5286e-05,\n",
       "                       5.3183e-05, 4.3324e-05, 3.5292e-05, 2.8750e-05, 2.3420e-05, 1.9078e-05,\n",
       "                       1.5542e-05, 1.2660e-05, 1.0313e-05, 8.4015e-06, 6.8440e-06, 5.5752e-06,\n",
       "                       4.5417e-06, 3.6997e-06, 3.0139e-06, 2.4551e-06], device='cuda:0')),\n",
       "              ('_cos_cached',\n",
       "               tensor([[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "                       [ 0.5403,  0.6861,  0.7878,  ...,  1.0000,  1.0000,  1.0000],\n",
       "                       [-0.4161, -0.0584,  0.2412,  ...,  1.0000,  1.0000,  1.0000],\n",
       "                       ...,\n",
       "                       [-0.4248, -0.2683,  0.7489,  ...,  0.9995,  0.9997,  0.9998],\n",
       "                       [-0.9913,  0.5166,  0.9982,  ...,  0.9995,  0.9997,  0.9998],\n",
       "                       [-0.6464,  0.9774,  0.8237,  ...,  0.9995,  0.9997,  0.9998]],\n",
       "                      device='cuda:0')),\n",
       "              ('_sin_cached',\n",
       "               tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "                         0.0000e+00,  0.0000e+00],\n",
       "                       [ 8.4147e-01,  7.2746e-01,  6.1596e-01,  ...,  3.6997e-06,\n",
       "                         3.0139e-06,  2.4551e-06],\n",
       "                       [ 9.0930e-01,  9.9829e-01,  9.7048e-01,  ...,  7.3994e-06,\n",
       "                         6.0277e-06,  4.9103e-06],\n",
       "                       ...,\n",
       "                       [ 9.0528e-01, -9.6334e-01, -6.6264e-01,  ...,  3.0292e-02,\n",
       "                         2.4678e-02,  2.0104e-02],\n",
       "                       [ 1.3166e-01, -8.5624e-01, -6.0722e-02,  ...,  3.0296e-02,\n",
       "                         2.4681e-02,  2.0106e-02],\n",
       "                       [-7.6301e-01, -2.1140e-01,  5.6696e-01,  ...,  3.0300e-02,\n",
       "                         2.4684e-02,  2.0109e-02]], device='cuda:0'))]),\n",
       " '_non_persistent_buffers_set': {'_cos_cached', '_sin_cached', 'inv_freq'},\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict(),\n",
       " 'scaling_factor': 1.0,\n",
       " 'dim': 128,\n",
       " 'max_position_embeddings': 8192,\n",
       " 'base': 500000.0,\n",
       " 'max_seq_len_cached': 8192,\n",
       " '_is_hf_initialized': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.layers[0].self_attn.rotary_emb.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = model.model.embed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rope = model.model.layers[0].self_attn.rotary_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.sparse.Embedding"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/data/yimin/models/base/meta-llama/Meta-Llama-3-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "input = tokenizer(['Hello, how are you today?', 'I am good'], padding=True, return_tensors=\"pt\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  9906,     11,   1268,    527,    499,   3432,     30],\n",
       "        [    40,   1097,   1695, 128001, 128001, 128001, 128001]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 0, 0, 0, 0]], device='cuda:0')}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input['input_ids']\n",
    "input_mask = input['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9287e-02, -8.3008e-03,  6.1951e-03,  ...,  2.6398e-03,\n",
       "          -3.2196e-03, -4.5586e-04],\n",
       "         [-2.0599e-04, -2.6703e-04,  1.7643e-05,  ...,  1.3638e-04,\n",
       "           1.1015e-04,  1.6022e-04],\n",
       "         [ 3.5286e-04, -4.7302e-03,  5.6763e-03,  ..., -8.6670e-03,\n",
       "          -5.2185e-03,  7.2937e-03],\n",
       "         ...,\n",
       "         [-6.5613e-03, -4.8828e-03, -2.4567e-03,  ..., -1.8005e-03,\n",
       "           6.5613e-04,  1.0443e-04],\n",
       "         [-7.3547e-03, -8.9111e-03,  3.2959e-03,  ..., -5.8899e-03,\n",
       "           1.9531e-03,  2.7771e-03],\n",
       "         [-4.9438e-03, -1.6098e-03,  6.4087e-03,  ...,  1.9989e-03,\n",
       "          -1.0147e-03, -4.8523e-03]],\n",
       "\n",
       "        [[ 7.0496e-03, -3.4904e-04, -6.9275e-03,  ..., -4.9133e-03,\n",
       "           6.1646e-03, -1.0300e-03],\n",
       "         [ 9.8877e-03, -1.4343e-03, -1.7090e-03,  ..., -6.4087e-03,\n",
       "          -9.3842e-04,  1.6022e-03],\n",
       "         [-4.6692e-03, -1.0925e-02, -2.9755e-03,  ..., -9.5215e-03,\n",
       "          -8.2397e-03,  7.3547e-03],\n",
       "         ...,\n",
       "         [-8.3542e-04,  1.9455e-03,  4.8256e-04,  ..., -1.8616e-03,\n",
       "           2.1057e-03,  1.6708e-03],\n",
       "         [-8.3542e-04,  1.9455e-03,  4.8256e-04,  ..., -1.8616e-03,\n",
       "           2.1057e-03,  1.6708e-03],\n",
       "         [-8.3542e-04,  1.9455e-03,  4.8256e-04,  ..., -1.8616e-03,\n",
       "           2.1057e-03,  1.6708e-03]]], device='cuda:0',\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_output = embedding(input_ids)\n",
    "embedding_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 4096])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_output.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 4096])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.model.embed_tokens(input_ids)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9906,   11, 1268,  527,  499, 3432,   30]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "## 保存模型\n",
    "torch.save(model.model.embed_tokens.state_dict(), 'embedding.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 读取模型\n",
    "# state_dict = torch.load('embedding.pth')\n",
    "# embedding = torch.nn.modules.sparse.Embedding(128256, 4096).to('cuda')\n",
    "# embedding.load_state_dict(state_dict)\n",
    "state_dict = torch.load('embedding.pth')\n",
    "embedding = torch.nn.modules.sparse.Embedding(state_dict['weight'].shape[0], state_dict['weight'].shape[1]).to('cuda')\n",
    "embedding.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['model']['weight'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128000"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.sparse.Embedding"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.model.embed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.sparse.Embedding"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = embedding(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 4096])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ 1.3733e-03,  5.0964e-03, -3.0365e-03,  ...,  2.2888e-03,\n",
       "                       -1.9531e-03, -1.7166e-05],\n",
       "                      [-2.7313e-03,  1.9379e-03, -1.3733e-03,  ..., -5.1498e-05,\n",
       "                       -1.3962e-03, -1.9836e-03],\n",
       "                      [ 9.5367e-04, -1.3367e-02,  4.1771e-04,  ...,  2.5940e-03,\n",
       "                        7.0496e-03,  4.1809e-03],\n",
       "                      ...,\n",
       "                      [ 1.8715e-23,  3.2699e-24,  1.8198e-23,  ...,  5.3767e-23,\n",
       "                       -2.2360e-24, -1.9852e-23],\n",
       "                      [ 1.9335e-23, -1.8612e-24, -1.8818e-23,  ...,  2.3368e-23,\n",
       "                        7.3412e-24, -3.1226e-23],\n",
       "                      [-7.4860e-23, -6.3693e-23,  5.5059e-24,  ...,  4.9631e-24,\n",
       "                       -5.4594e-23, -2.2877e-24]], device='cuda:0'))])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.embed_tokens.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128256"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.embed_tokens.num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(128256, 4096)\n"
     ]
    }
   ],
   "source": [
    "print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': OrderedDict([('weight',\n",
       "               Parameter containing:\n",
       "               tensor([[ 1.3733e-03,  5.0964e-03, -3.0365e-03,  ...,  2.2888e-03,\n",
       "                        -1.9531e-03, -1.7166e-05],\n",
       "                       [-2.7313e-03,  1.9379e-03, -1.3733e-03,  ..., -5.1498e-05,\n",
       "                        -1.3962e-03, -1.9836e-03],\n",
       "                       [ 9.5367e-04, -1.3367e-02,  4.1771e-04,  ...,  2.5940e-03,\n",
       "                         7.0496e-03,  4.1809e-03],\n",
       "                       ...,\n",
       "                       [ 1.8715e-23,  3.2699e-24,  1.8198e-23,  ...,  5.3767e-23,\n",
       "                        -2.2360e-24, -1.9852e-23],\n",
       "                       [ 1.9335e-23, -1.8612e-24, -1.8818e-23,  ...,  2.3368e-23,\n",
       "                         7.3412e-24, -3.1226e-23],\n",
       "                       [-7.4860e-23, -6.3693e-23,  5.5059e-24,  ...,  4.9631e-24,\n",
       "                        -5.4594e-23, -2.2877e-24]], device='cuda:0', requires_grad=True))]),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict(),\n",
       " 'num_embeddings': 128256,\n",
       " 'embedding_dim': 4096,\n",
       " 'padding_idx': None,\n",
       " 'max_norm': None,\n",
       " 'norm_type': 2.0,\n",
       " 'scale_grad_by_freq': False,\n",
       " 'sparse': False,\n",
       " '_is_hf_initialized': True,\n",
       " '_old_forward': <bound method Embedding.forward of Embedding(128256, 4096)>,\n",
       " '_hf_hook': AlignDevicesHook(execution_device=0, offload=False, io_same_device=False, offload_buffers=False, place_submodules=True, skip_keys=['past_key_values', 'causal_mask']),\n",
       " 'forward': functools.partial(<function add_hook_to_module.<locals>.new_forward at 0x7f09bc49dd80>, Embedding(128256, 4096))}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.embed_tokens.__dict__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend",
   "language": "python",
   "name": "backend"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
